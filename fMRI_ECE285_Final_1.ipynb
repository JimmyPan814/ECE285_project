{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1d1bfd",
   "metadata": {},
   "source": [
    "## ECE 285 - Final Project\n",
    "## Training a neural network to predict image category using functional magnetic resonance imaging (fMRI) signals.\n",
    "###  Instructor: Xiaolong WANG\n",
    "*****************************************************************************************************************\n",
    "Shayne Wang, A15776202, June 2023\n",
    "\n",
    "ECE MLDS, UCSD\n",
    "\n",
    "Bochen Pan, A15562542, June 2023\n",
    "\n",
    "ECE MLDS, UCSD\n",
    "******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a34a06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "#from torch.utils.data import Dataset\n",
    "#import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "#import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "np.random.seed(0)\n",
    "#os.chdir('C:/0-ece285/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d52c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject                         image_id  LHEarlyVis#0  LHEarlyVis#1  \\\n",
      "0        1             n01930112_19568.JPEG      0.167271      1.173377   \n",
      "1        1             n03733281_29214.JPEG      1.258984      0.744704   \n",
      "2        1              n07695742_5848.JPEG      0.279666     -0.164892   \n",
      "3        1  COCO_train2014_000000420713.jpg      0.473376     -0.299339   \n",
      "4        1  COCO_train2014_000000488558.jpg      0.224416      1.852141   \n",
      "\n",
      "   LHEarlyVis#2  LHEarlyVis#3  LHEarlyVis#4  LHEarlyVis#5  LHEarlyVis#6  \\\n",
      "0     -0.482830      0.561836      0.487629     -1.366299      0.526726   \n",
      "1      0.264117     -0.199035      0.221795     -1.114712      0.549931   \n",
      "2     -0.550474      0.587374      0.319142     -0.022280      1.146169   \n",
      "3      0.365422      0.443424      0.986940      0.916352      0.656573   \n",
      "4      1.087473     -0.393302      0.129446      0.858346     -0.352569   \n",
      "\n",
      "   LHEarlyVis#7  ...  RHRSC#134  RHRSC#135  RHRSC#136  RHRSC#137  RHRSC#138  \\\n",
      "0      0.645983  ...  -0.597951  -0.857890   0.852635  -0.529717  -0.255397   \n",
      "1      0.281665  ...   0.446233   0.367790   1.029251   0.701042  -0.103289   \n",
      "2      0.274503  ...  -0.157985   0.355208  -0.401276   0.750957   0.218266   \n",
      "3      0.862030  ...  -0.963717   0.407181  -0.304874  -0.188305   0.730949   \n",
      "4      1.769888  ...   0.626630   0.597541  -0.532779   0.920447   1.013526   \n",
      "\n",
      "   RHRSC#139  RHRSC#140  RHRSC#141  RHRSC#142  category  \n",
      "0  -0.445352   0.759584   0.468859   0.463002    animal  \n",
      "1  -0.766774   0.224465  -0.265740   0.432070  artifact  \n",
      "2   1.430320  -0.202340   0.537166   1.201923      food  \n",
      "3   0.136514   0.574487  -0.220459  -0.503594      food  \n",
      "4   0.267579   0.996452  -0.202705  -1.610582    animal  \n",
      "\n",
      "[5 rows x 1688 columns]\n",
      "shape of data (5029, 1685) (5029,)\n",
      "{'food': 0, 'animal': 1, 'event': 2, 'person': 3, 'plant': 4, 'artifact': 5, 'entity': 6}\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#  Section 1: DATA IMPORT\n",
    "#  We import the dataset in .csv format and convert it into a data frame\n",
    "#  The dataset has been divided into 4 files. \n",
    "#  Generate X and Y in numpy from data frame\n",
    "###################################################################################\n",
    "pd_fMRI_1 = pd.read_csv('df_merged_subject1.csv')\n",
    "#pd_fMRI_2 = pd.read_csv('.\\data\\df_merged_subject2.csv')\n",
    "#pd_fMRI_3 = pd.read_csv('.\\data\\df_merged_subject3.csv')\n",
    "#pd_fMRI_4 = pd.read_csv('.\\data\\df_merged_subject4.csv')\n",
    "\n",
    "#pd_fMRI = pd.concat([pd_fMRI_1,pd_fMRI_2,pd_fMRI_3,pd_fMRI_4])\n",
    "\n",
    "# display the 5 lines of the data frame\n",
    "print(pd_fMRI_1.head())\n",
    "\n",
    "# generate X and Y in numpy\n",
    "X_data = pd_fMRI_1.values[:,2:-1].astype(float)\n",
    "Y_data = pd_fMRI_1.values[:,-1]\n",
    "print('shape of data', X_data.shape, Y_data.shape)\n",
    "\n",
    "# filter out the name of categories\n",
    "Y_class = set(Y_data.tolist())\n",
    "# create a dictionary for category vs index\n",
    "class_dict = dict(zip(Y_class,range(len(Y_class))))\n",
    "print(class_dict)\n",
    "\n",
    "# convert category Y into integer since PyTorch doesn't have dtype for string\n",
    "Y_data = np.array([class_dict.get(a_class) for a_class in Y_data.tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54e3d6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#  Section 2: DATA PREPROCESSING AND SPLIT\n",
    "#  Preprocess the data in this section\n",
    "#  Split the dataset into validation : test = 80% : 20% . \n",
    "###################################################################################\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Option to use GPU\n",
    "#USE_GPU = False  # Dad can not use GPU\n",
    "USE_GPU = True\n",
    "num_class = len(class_dict)\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if USE_GPU else torch.FloatTensor\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# convert numpy arrays to tensors, then encapsulate as a dataset (X,Y) ready to split\n",
    "dataset = TensorDataset(Tensor(X_data), Tensor(Y_data))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c5bf8",
   "metadata": {},
   "source": [
    "# Model 1 neural network without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e3c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/126], Loss: 0.9962\n",
      "Epoch [2/10], Step [100/126], Loss: 0.7680\n",
      "Epoch [3/10], Step [100/126], Loss: 0.5321\n",
      "Epoch [4/10], Step [100/126], Loss: 0.3983\n",
      "Epoch [5/10], Step [100/126], Loss: 0.0864\n",
      "Epoch [6/10], Step [100/126], Loss: 0.0697\n",
      "Epoch [7/10], Step [100/126], Loss: 0.0249\n",
      "Epoch [8/10], Step [100/126], Loss: 0.0167\n",
      "Epoch [9/10], Step [100/126], Loss: 0.0105\n",
      "Epoch [10/10], Step [100/126], Loss: 0.0080\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "input_size = X_data.shape[1]  # number of features in the input\n",
    "hidden_size = 100  # You can change this value\n",
    "output_size = len(class_dict)  # number of classes in the output\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # You can change the learning rate\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10  # You can change the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if (i+1) % print_every == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_dataloader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3ec1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 79.96031746031746 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Turn off gradients for this block\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693632b5",
   "metadata": {},
   "source": [
    "# Model with Dropout and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32d3c1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/126], Loss: 1.3221\n",
      "Validation accuracy is: 52.788844621513945 %, loss is: 1.1903143301606178\n",
      "Epoch [2/10], Step [100/126], Loss: 1.0487\n",
      "Validation accuracy is: 55.57768924302789 %, loss is: 1.1702259480953217\n",
      "Epoch [3/10], Step [100/126], Loss: 0.7791\n",
      "Validation accuracy is: 53.386454183266935 %, loss is: 1.1971449740231037\n",
      "Epoch [4/10], Step [100/126], Loss: 0.9117\n",
      "Validation accuracy is: 51.79282868525896 %, loss is: 1.231712929904461\n",
      "Epoch [5/10], Step [100/126], Loss: 0.6955\n",
      "Validation accuracy is: 52.191235059760956 %, loss is: 1.2543550245463848\n",
      "Epoch [6/10], Step [100/126], Loss: 0.6235\n",
      "Validation accuracy is: 53.386454183266935 %, loss is: 1.310781192034483\n",
      "Epoch [7/10], Step [100/126], Loss: 0.6007\n",
      "Validation accuracy is: 50.59760956175299 %, loss is: 1.3456846699118614\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the model with Dropout and Batch Normalization\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_prob=0.5):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)  # Batch Normalization after first layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Dropout layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler for learning rate decay\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Early stopping initialization\n",
    "n_epochs_stop = 5\n",
    "min_val_loss = np.Inf\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if (i+1) % print_every == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_dataloader), loss.item()))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        val_loss = 0\n",
    "        for images, labels in valid_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        val_loss = val_loss/len(valid_dataloader)\n",
    "\n",
    "        print('Validation accuracy is: {} %, loss is: {}'.format(100 * correct / total, val_loss))\n",
    "\n",
    "    # Early stopping\n",
    "    if min_val_loss > val_loss:\n",
    "        epochs_no_improve = 0\n",
    "        min_val_loss = val_loss\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == n_epochs_stop:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a5a1858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 58.73015873015873 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Turn off gradients for this block\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c9ef2",
   "metadata": {},
   "source": [
    "# Model with Dropout and Batch Normalization with more complexity and more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "423f60e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/126], Loss: 1.4661\n",
      "Validation accuracy is: 52.39043824701195 %, loss is: 1.2184390909969807\n",
      "Epoch [2/10], Step [100/126], Loss: 1.1219\n",
      "Validation accuracy is: 54.581673306772906 %, loss is: 1.1902594044804573\n",
      "Epoch [3/10], Step [100/126], Loss: 1.4515\n",
      "Validation accuracy is: 56.77290836653386 %, loss is: 1.1652898080646992\n",
      "Epoch [4/10], Step [100/126], Loss: 1.3032\n",
      "Validation accuracy is: 58.167330677290835 %, loss is: 1.162667192518711\n",
      "Epoch [5/10], Step [100/126], Loss: 0.8456\n",
      "Validation accuracy is: 57.76892430278885 %, loss is: 1.1601295173168182\n",
      "Epoch [6/10], Step [100/126], Loss: 1.0854\n",
      "Validation accuracy is: 56.17529880478088 %, loss is: 1.166124615818262\n",
      "Epoch [7/10], Step [100/126], Loss: 0.6936\n",
      "Validation accuracy is: 54.38247011952191 %, loss is: 1.2391556948423386\n",
      "Epoch [8/10], Step [100/126], Loss: 0.4609\n",
      "Validation accuracy is: 55.57768924302789 %, loss is: 1.2728989943861961\n",
      "Epoch [9/10], Step [100/126], Loss: 0.8803\n",
      "Validation accuracy is: 54.581673306772906 %, loss is: 1.2986496835947037\n",
      "Epoch [10/10], Step [100/126], Loss: 0.7570\n",
      "Validation accuracy is: 53.78486055776892 %, loss is: 1.327348843216896\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the model with Dropout and Batch Normalization with more complexity and more layers\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size2, output_size, dropout_prob=0.5):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)  # Batch Normalization after first layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Dropout layer\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size2)  # Second hidden layer\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size2)  # Batch Normalization after second layer\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "hidden_size2 = 200  # Size of the second hidden layer, you can change this value\n",
    "model = NeuralNetwork(input_size, hidden_size, hidden_size2, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler for learning rate decay\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Early stopping initialization\n",
    "n_epochs_stop = 5\n",
    "min_val_loss = np.Inf\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if (i+1) % print_every == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_dataloader), loss.item()))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        val_loss = 0\n",
    "        for images, labels in valid_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        val_loss = val_loss/len(valid_dataloader)\n",
    "\n",
    "        print('Validation accuracy is: {} %, loss is: {}'.format(100 * correct / total, val_loss))\n",
    "\n",
    "    # Early stopping\n",
    "    if min_val_loss > val_loss:\n",
    "        epochs_no_improve = 0\n",
    "        min_val_loss = val_loss\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == n_epochs_stop:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1526022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 49.007936507936506 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()  # it's important to switch to eval mode for testing\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5600f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dataloader to feed the model\n",
    "def train():\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a48796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91b912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "885ad61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cd22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9058df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
