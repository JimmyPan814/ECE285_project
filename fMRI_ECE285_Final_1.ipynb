{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1d1bfd",
   "metadata": {},
   "source": [
    "## ECE 285 - Final Project\n",
    "## Training a neural network to predict image category using functional magnetic resonance imaging (fMRI) signals.\n",
    "###  Instructor: Xiaolong WANG\n",
    "*****************************************************************************************************************\n",
    "Shayne Wang, A15776202, June 2023\n",
    "\n",
    "ECE MLDS, UCSD\n",
    "******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34a06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "#from torch.utils.data import Dataset\n",
    "#import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "#import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "np.random.seed(0)\n",
    "os.chdir('C:/0-ece285/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d52c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject                         image_id  LHEarlyVis#0  LHEarlyVis#1  \\\n",
      "0        1             n01930112_19568.JPEG      0.167271      1.173377   \n",
      "1        1             n03733281_29214.JPEG      1.258984      0.744704   \n",
      "2        1              n07695742_5848.JPEG      0.279666     -0.164892   \n",
      "3        1  COCO_train2014_000000420713.jpg      0.473376     -0.299339   \n",
      "4        1  COCO_train2014_000000488558.jpg      0.224416      1.852141   \n",
      "\n",
      "   LHEarlyVis#2  LHEarlyVis#3  LHEarlyVis#4  LHEarlyVis#5  LHEarlyVis#6  \\\n",
      "0     -0.482830      0.561836      0.487629     -1.366299      0.526726   \n",
      "1      0.264117     -0.199035      0.221795     -1.114712      0.549931   \n",
      "2     -0.550474      0.587374      0.319142     -0.022280      1.146169   \n",
      "3      0.365422      0.443424      0.986940      0.916352      0.656573   \n",
      "4      1.087473     -0.393302      0.129446      0.858346     -0.352569   \n",
      "\n",
      "   LHEarlyVis#7  ...  RHRSC#134  RHRSC#135  RHRSC#136  RHRSC#137  RHRSC#138  \\\n",
      "0      0.645983  ...  -0.597951  -0.857890   0.852635  -0.529717  -0.255397   \n",
      "1      0.281665  ...   0.446233   0.367790   1.029251   0.701042  -0.103289   \n",
      "2      0.274503  ...  -0.157985   0.355208  -0.401276   0.750957   0.218266   \n",
      "3      0.862030  ...  -0.963717   0.407181  -0.304874  -0.188305   0.730949   \n",
      "4      1.769888  ...   0.626630   0.597541  -0.532779   0.920447   1.013526   \n",
      "\n",
      "   RHRSC#139  RHRSC#140  RHRSC#141  RHRSC#142  category  \n",
      "0  -0.445352   0.759584   0.468859   0.463002    animal  \n",
      "1  -0.766774   0.224465  -0.265740   0.432070  artifact  \n",
      "2   1.430320  -0.202340   0.537166   1.201923      food  \n",
      "3   0.136514   0.574487  -0.220459  -0.503594      food  \n",
      "4   0.267579   0.996452  -0.202705  -1.610582    animal  \n",
      "\n",
      "[5 rows x 1688 columns]\n",
      "shape of data (5029, 1685) (5029,)\n",
      "{'food': 0, 'animal': 1, 'plant': 2, 'event': 3, 'person': 4, 'entity': 5, 'artifact': 6}\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#  Section 1: DATA IMPORT\n",
    "#  We import the dataset in .csv format and convert it into a data frame\n",
    "#  The dataset has been divided into 4 files. \n",
    "#  Generate X and Y in numpy from data frame\n",
    "###################################################################################\n",
    "pd_fMRI_1 = pd.read_csv('.\\data\\df_merged_subject1.csv')\n",
    "#pd_fMRI_2 = pd.read_csv('.\\data\\df_merged_subject2.csv')\n",
    "#pd_fMRI_3 = pd.read_csv('.\\data\\df_merged_subject3.csv')\n",
    "#pd_fMRI_4 = pd.read_csv('.\\data\\df_merged_subject4.csv')\n",
    "\n",
    "#pd_fMRI = pd.concat([pd_fMRI_1,pd_fMRI_2,pd_fMRI_3,pd_fMRI_4])\n",
    "\n",
    "# display the 5 lines of the data frame\n",
    "print(pd_fMRI_1.head())\n",
    "\n",
    "# generate X and Y in numpy\n",
    "X_data = pd_fMRI_1.values[:,2:-1].astype(float)\n",
    "Y_data = pd_fMRI_1.values[:,-1]\n",
    "print('shape of data', X_data.shape, Y_data.shape)\n",
    "\n",
    "# filter out the name of categories\n",
    "Y_class = set(Y_data.tolist())\n",
    "# create a dictionary for category vs index\n",
    "class_dict = dict(zip(Y_class,range(len(Y_class))))\n",
    "print(class_dict)\n",
    "\n",
    "# convert category Y into integer since PyTorch doesn't have dtype for string\n",
    "Y_data = np.array([class_dict.get(a_class) for a_class in Y_data.tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e3d6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#  Section 2: DATA PREPROCESSING AND SPLIT\n",
    "#  Preprocess the data in this section\n",
    "#  Split the dataset into validation : test = 80% : 20% . \n",
    "###################################################################################\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Option to use GPU\n",
    "USE_GPU = False  # Dad can not use GPU\n",
    "num_class = len(class_dict)\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if USE_GPU else torch.FloatTensor\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# convert numpy arrays to tensors, then encapsulate as a dataset (X,Y) ready to split\n",
    "dataset = TensorDataset(Tensor(X_data), Tensor(Y_data))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use dataloader to feed the model\n",
    "def train():\n",
    "\n",
    "def evaluate():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc1470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "885ad61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1cd22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9058df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
