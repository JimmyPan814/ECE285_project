{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fb1d1bfd",
      "metadata": {
        "id": "fb1d1bfd"
      },
      "source": [
        "## ECE 285 - Final Project\n",
        "## Training a neural network to predict image category using functional magnetic resonance imaging (fMRI) signals.\n",
        "### Instructor: Xiaolong WANG\n",
        "*****************************************************************************************************************\n",
        "Shayne Wang, A15776202, June 2023\n",
        "******************************************************************************************************************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a34a06e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a34a06e5",
        "outputId": "1e1aeda7-d862-4784-d716-e676a7752222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#from torch.utils.data import Dataset\n",
        "#import torchvision\n",
        "#import torchvision.transforms as transforms\n",
        "#import torchvision.transforms as T\n",
        "\n",
        "# Option to use GPU\n",
        "USE_GPU = True  \n",
        "\n",
        "dtype = torch.float32 \n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print('using device:', device)\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if USE_GPU else torch.FloatTensor\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c7d52c97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7d52c97",
        "outputId": "8fade7dc-43fe-49bf-bc20-13b14bf75e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "   subject                         image_id  LHEarlyVis#0  LHEarlyVis#1  \\\n",
            "0        1             n01930112_19568.JPEG      0.167271      1.173377   \n",
            "1        1             n03733281_29214.JPEG      1.258984      0.744704   \n",
            "2        1              n07695742_5848.JPEG      0.279666     -0.164892   \n",
            "3        1  COCO_train2014_000000420713.jpg      0.473376     -0.299339   \n",
            "4        1  COCO_train2014_000000488558.jpg      0.224416      1.852141   \n",
            "\n",
            "   LHEarlyVis#2  LHEarlyVis#3  LHEarlyVis#4  LHEarlyVis#5  LHEarlyVis#6  \\\n",
            "0     -0.482830      0.561836      0.487629     -1.366299      0.526726   \n",
            "1      0.264117     -0.199035      0.221795     -1.114712      0.549931   \n",
            "2     -0.550474      0.587374      0.319142     -0.022280      1.146169   \n",
            "3      0.365422      0.443424      0.986940      0.916352      0.656573   \n",
            "4      1.087473     -0.393302      0.129446      0.858346     -0.352569   \n",
            "\n",
            "   LHEarlyVis#7  ...  RHRSC#134  RHRSC#135  RHRSC#136  RHRSC#137  RHRSC#138  \\\n",
            "0      0.645983  ...  -0.597951  -0.857890   0.852635  -0.529717  -0.255397   \n",
            "1      0.281665  ...   0.446233   0.367790   1.029251   0.701042  -0.103289   \n",
            "2      0.274503  ...  -0.157985   0.355208  -0.401276   0.750957   0.218266   \n",
            "3      0.862030  ...  -0.963717   0.407181  -0.304874  -0.188305   0.730949   \n",
            "4      1.769888  ...   0.626630   0.597541  -0.532779   0.920447   1.013526   \n",
            "\n",
            "   RHRSC#139  RHRSC#140  RHRSC#141  RHRSC#142  category  \n",
            "0  -0.445352   0.759584   0.468859   0.463002    animal  \n",
            "1  -0.766774   0.224465  -0.265740   0.432070  artifact  \n",
            "2   1.430320  -0.202340   0.537166   1.201923      food  \n",
            "3   0.136514   0.574487  -0.220459  -0.503594      food  \n",
            "4   0.267579   0.996452  -0.202705  -1.610582    animal  \n",
            "\n",
            "[5 rows x 1688 columns]\n",
            "shape of data:  (5029, 1685) (5029,)\n",
            "class in this dataset:\n",
            " {'plant': 0, 'animal': 1, 'event': 2, 'artifact': 3, 'person': 4, 'entity': 5, 'food': 6}\n",
            "****************************************************************************************************\n",
            "****************************************************************************************************\n",
            "   subject                             image_id  LHEarlyVis#0  LHEarlyVis#1  \\\n",
            "0        2                 n09468604_12427.JPEG      0.851023      0.536749   \n",
            "1        2                  n01494475_3853.JPEG     -0.572237     -0.335348   \n",
            "2        2  rep_COCO_train2014_000000312003.jpg      0.921910      1.293384   \n",
            "3        2      COCO_train2014_000000441891.jpg      0.275849      1.127995   \n",
            "4        2      COCO_train2014_000000408922.jpg      0.662984      1.375250   \n",
            "\n",
            "   LHEarlyVis#2  LHEarlyVis#3  LHEarlyVis#4  LHEarlyVis#5  LHEarlyVis#6  \\\n",
            "0      0.359691      0.062843     -0.513640     -0.069796      1.162859   \n",
            "1     -0.219275     -0.708724     -0.615195     -0.292575     -0.619620   \n",
            "2     -0.183662      0.946978     -0.512321      0.775329      0.407812   \n",
            "3      0.226533      0.328003      0.130328      0.242693     -0.094467   \n",
            "4     -0.193374      0.511180      0.510498     -0.748977      0.348296   \n",
            "\n",
            "   LHEarlyVis#7  ...  RHRSC#16  RHRSC#17  RHRSC#18  RHRSC#19  RHRSC#20  \\\n",
            "0      0.021384  ... -0.030668  1.836696  1.089949  0.358044 -1.031410   \n",
            "1     -0.430547  ... -0.494160  0.426972  0.236856 -0.413165  0.506542   \n",
            "2      0.611241  ...  1.817472  1.648172  1.482203  0.701630  1.342594   \n",
            "3      0.134127  ... -0.851278 -0.013021 -2.224507 -1.869585 -0.498654   \n",
            "4     -0.635568  ... -1.688971 -1.861510 -0.409155  0.082622 -1.849953   \n",
            "\n",
            "   RHRSC#21  RHRSC#22  RHRSC#23  RHRSC#24  category  \n",
            "0 -0.809087 -2.908010 -0.592262 -1.375098    entity  \n",
            "1  0.868839 -1.165283 -0.552089  0.602817    person  \n",
            "2  1.740287  0.584208  1.997355  0.290470  artifact  \n",
            "3 -0.679905 -0.634095 -0.188820  1.548740  artifact  \n",
            "4 -1.270522 -1.152795  0.725050 -1.354557  artifact  \n",
            "\n",
            "[5 rows x 1231 columns]\n",
            "shape of data:  (5029, 1228) (5029,)\n",
            "class in this dataset:\n",
            " {'plant': 0, 'animal': 1, 'artifact': 2, 'event': 3, 'person': 4, 'entity': 5, 'food': 6}\n",
            "****************************************************************************************************\n",
            "****************************************************************************************************\n",
            "   subject                         image_id  LHEarlyVis#0  LHEarlyVis#1  \\\n",
            "0        3  COCO_train2014_000000292845.jpg      1.238665      0.404795   \n",
            "1        3  COCO_train2014_000000296474.jpg      0.442644      1.240564   \n",
            "2        3  COCO_train2014_000000340488.jpg     -0.068887     -0.074017   \n",
            "3        3  COCO_train2014_000000072095.jpg     -1.302105     -1.338536   \n",
            "4        3  COCO_train2014_000000207833.jpg     -0.841807     -0.990209   \n",
            "\n",
            "   LHEarlyVis#2  LHEarlyVis#3  LHEarlyVis#4  LHEarlyVis#5  LHEarlyVis#6  \\\n",
            "0      0.977252      0.022144     -0.981377      0.215708     -0.219328   \n",
            "1      0.828025     -0.017332      0.351841      0.202542      0.695263   \n",
            "2      0.400164     -0.210570      0.207279     -0.461544     -0.349052   \n",
            "3     -0.599421     -0.207713     -0.747719     -1.049721     -1.139335   \n",
            "4      0.090210     -0.821574     -0.310257      0.081427      0.261807   \n",
            "\n",
            "   LHEarlyVis#7  ...  RHRSC#107  RHRSC#108  RHRSC#109  RHRSC#110  RHRSC#111  \\\n",
            "0     -0.323567  ...  -1.178601   0.031885  -1.207737  -0.637837  -1.159053   \n",
            "1      0.800276  ...   0.398494  -0.929266  -0.516666  -0.149597  -0.538742   \n",
            "2     -0.630098  ...  -0.586935  -0.945950   0.182821  -0.044410   0.225019   \n",
            "3      0.115096  ...  -0.971755  -2.248353  -0.854727  -0.268359   0.034369   \n",
            "4     -0.117169  ...  -1.840234   0.778840   0.519648  -1.494047  -1.030135   \n",
            "\n",
            "   RHRSC#112  RHRSC#113  RHRSC#114  RHRSC#115  category  \n",
            "0  -0.709683   0.369193   0.181166   0.567739  artifact  \n",
            "1  -0.560314   0.452903   0.521449   0.952557  artifact  \n",
            "2   0.114756   0.545004   0.251926  -0.961105  artifact  \n",
            "3   0.050910   0.402734  -1.496345  -0.226965    entity  \n",
            "4  -2.575423  -1.720251  -1.023065  -0.776835  artifact  \n",
            "\n",
            "[5 rows x 1579 columns]\n",
            "shape of data:  (5029, 1576) (5029,)\n",
            "class in this dataset:\n",
            " {'plant': 0, 'animal': 1, 'event': 2, 'artifact': 3, 'person': 4, 'entity': 5, 'food': 6}\n",
            "****************************************************************************************************\n",
            "****************************************************************************************************\n",
            "   subject                         image_id  LHEarlyVis#0  LHEarlyVis#1  \\\n",
            "0        4  COCO_train2014_000000292845.jpg     -0.239394     -1.106235   \n",
            "1        4  COCO_train2014_000000081476.jpg      0.975071      0.193896   \n",
            "2        4              n04209133_8326.JPEG      1.805209      0.007243   \n",
            "3        4                 banquetHall2.jpg     -1.446333     -1.012778   \n",
            "4        4              n02002556_6108.JPEG      0.270110     -0.305940   \n",
            "\n",
            "   LHEarlyVis#2  LHEarlyVis#3  LHEarlyVis#4  LHEarlyVis#5  LHEarlyVis#6  \\\n",
            "0     -1.691824     -0.977981     -0.957937     -0.783785     -0.904331   \n",
            "1     -1.164289      1.163958     -0.429163      0.019751     -0.364615   \n",
            "2     -1.245437      0.915273     -0.591381     -0.768234     -0.694422   \n",
            "3     -0.658140     -0.111417     -0.878914     -1.603490      1.153656   \n",
            "4     -1.089673     -0.113713     -0.254007     -0.753484      0.665728   \n",
            "\n",
            "   LHEarlyVis#7  ...  RHRSC#133  RHRSC#134  RHRSC#135  RHRSC#136  RHRSC#137  \\\n",
            "0     -1.724815  ...  -1.187785   0.289676   0.216745   0.766065  -0.175697   \n",
            "1      1.126879  ...  -1.458698  -0.691946  -0.341818  -0.637648   0.195609   \n",
            "2     -0.968820  ...  -0.674007  -0.885567  -0.439321  -1.435557  -1.845175   \n",
            "3     -1.090256  ...  -0.611365  -0.279802  -0.112439  -0.038965  -0.728193   \n",
            "4     -0.691775  ...   2.295392   1.379414   0.185492   0.187495   2.248572   \n",
            "\n",
            "   RHRSC#138  RHRSC#139  RHRSC#140  RHRSC#141  category  \n",
            "0  -1.268519  -1.155133  -0.609946  -1.327631  artifact  \n",
            "1   0.216088   0.793233   0.054272   0.034010    animal  \n",
            "2  -1.284968  -1.284246  -1.446180  -0.144104  artifact  \n",
            "3   0.282098  -0.713987  -0.348690  -0.145065    entity  \n",
            "4   1.139685   0.129522   1.022709   0.380120    animal  \n",
            "\n",
            "[5 rows x 2790 columns]\n",
            "shape of data:  (3007, 2787) (3007,)\n",
            "class in this dataset:\n",
            " {'plant': 0, 'animal': 1, 'artifact': 2, 'event': 3, 'person': 4, 'entity': 5, 'food': 6}\n",
            "****************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "###################################################################################\n",
        "#  Section 1: DATA IMPORT\n",
        "#  We import the dataset in .csv format and convert each into a data frame\n",
        "#  The dataset has been divided into 4 files. Note that each file has different\n",
        "#  number of columns.\n",
        "#  Generate X and Y in numpy from data frame\n",
        "###################################################################################\n",
        "\n",
        "def importData(file_name):\n",
        "    \"\"\"\n",
        "    Convert data in a csv file to numpy\n",
        "    \n",
        "    Inputs:\n",
        "    - one of the csv file name for dataset\n",
        "    \n",
        "    Returns: \n",
        "    - X: 2-D tensor, float32 \n",
        "    - Y: 1-D tensor, int\n",
        "    - class_dict: a dictionary for the classes in this dataset\n",
        "    \"\"\"\n",
        "    # read in csv file and convert to data frame\n",
        "    pd_fMRI = pd.read_csv(file_name)\n",
        "\n",
        "    # display the 5 lines of the data frame\n",
        "    print('*'*100)\n",
        "    print(pd_fMRI.head())\n",
        "\n",
        "    # generate X and Y in numpy\n",
        "    X = pd_fMRI.values[:,2:-1].astype(float)\n",
        "    Y = pd_fMRI.values[:,-1]\n",
        "    print('shape of data: ', X.shape, Y.shape)\n",
        "\n",
        "    # filter out the name of categories\n",
        "    Y_class = set(Y.tolist())\n",
        "    # create a dictionary for category vs index\n",
        "    class_dict = dict(zip(Y_class,range(len(Y_class))))\n",
        "    print('class in this dataset:\\n',class_dict)\n",
        "    print('*'*100)\n",
        "    # convert category Y into integer since PyTorch doesn't have dtype for string\n",
        "    Y = np.array([class_dict.get(a_class) for a_class in Y.tolist()])\n",
        "    return Tensor(X),Tensor(Y),class_dict\n",
        "\n",
        "# read out 4 csv files\n",
        "X_data_1, Y_data_1, class_dict_1 = importData('df_merged_subject1.csv')\n",
        "X_data_2, Y_data_2, class_dict_2 = importData('df_merged_subject2.csv')\n",
        "X_data_3, Y_data_3, class_dict_3 = importData('df_merged_subject3.csv')\n",
        "X_data_4, Y_data_4, class_dict_4 = importData('df_merged_subject4.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "54e3d6ab",
      "metadata": {
        "id": "54e3d6ab"
      },
      "outputs": [],
      "source": [
        "###################################################################################\n",
        "#  Section 2: DATA PREPROCESSING AND SPLIT\n",
        "#  Preprocess the data in this section\n",
        "#  Split the dataset into training:validation:test = 80%:10%:10%. \n",
        "###################################################################################\n",
        "\n",
        "def createLoader(X_data,Y_data,batch_size):\n",
        "    \"\"\"\n",
        "    Generate 3 dataloader for training, val and test sets.\n",
        "    \n",
        "    Inputs:\n",
        "    - X_data,Y_data: tensor, dataset ready for split\n",
        "    - batch_size: int, number of batch size fed to the model at a time\n",
        "    \n",
        "    Returns: \n",
        "    - 3 loader respectively for training, val and test sets \n",
        "    \"\"\"\n",
        "    # Encapsulate as a dataset (X,Y) ready to split\n",
        "    dataset = TensorDataset(X_data, Y_data)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = int(0.1 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    \n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "    \n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    return train_dataloader,valid_dataloader,test_dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e6e6e526",
      "metadata": {
        "id": "e6e6e526"
      },
      "outputs": [],
      "source": [
        "###################################################################################\n",
        "#  Section 3: A TRAINING LOOP AND CHECK ACCURACY FUNCTIONS\n",
        "#  Used to train any SELF-DEFINED MODEL and return accuracy on training set\n",
        "#  check_accuracy_part34 return accuracy of dataloadfer.\n",
        "###################################################################################\n",
        "# use dataloader to feed the model\n",
        "def train_part34(model, train_dataloader, valid_dataloader, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    A training loop\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - train_dataloader, valid_dataloader: the data loaders for training and val sets.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: The accuracy of the model\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(train_dataloader):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if (t + 1) % print_every == 0:\n",
        "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t + 1, loss.item()))\n",
        "                check_accuracy_part34(valid_dataloader, model, isTestSet=False)\n",
        "                print()\n",
        "    return check_accuracy_part34(valid_dataloader, model, isTestSet=False)\n",
        "\n",
        "\n",
        "def check_accuracy_part34(loader, model, isTestSet=True):\n",
        "    \n",
        "    if isTestSet:\n",
        "        print('Checking accuracy on test set')\n",
        "    else:\n",
        "        print('Checking accuracy on validation set') \n",
        "    \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4edc1470",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4edc1470",
        "outputId": "6772ba95-e2cc-443d-edca-2707f6192fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************************************\n",
            "Checking accuracy on validation set\n",
            "Got 289 / 502 correct (57.57)\n",
            "Checking accuracy on test set\n",
            "Got 290 / 504 correct (57.54)\n",
            "************************************************************\n",
            "Checking accuracy on validation set\n",
            "Got 254 / 502 correct (50.60)\n",
            "Checking accuracy on test set\n",
            "Got 273 / 504 correct (54.17)\n",
            "************************************************************\n",
            "Checking accuracy on validation set\n",
            "Got 271 / 502 correct (53.98)\n",
            "Checking accuracy on test set\n",
            "Got 269 / 504 correct (53.37)\n",
            "************************************************************\n",
            "Checking accuracy on validation set\n",
            "Got 163 / 300 correct (54.33)\n",
            "Checking accuracy on test set\n",
            "Got 164 / 302 correct (54.30)\n",
            "************************************************************\n"
          ]
        }
      ],
      "source": [
        "###################################################################################\n",
        "#  Section 4: Model 1\n",
        "#  Define a 2-layer MLP. \n",
        "#  This is a baseline\n",
        "###################################################################################\n",
        "\n",
        "learning_rate = 1e-3\n",
        "hidden_layer_size = 256\n",
        "epochs = 100\n",
        "batch_size = 512\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "\n",
        "def testModel1(X_data, Y_data, class_dict):\n",
        "    \"\"\"\n",
        "    Define, train and test a MLP model \n",
        "    \n",
        "    Inputs:\n",
        "    - Tensors and the dictionary for a csv file\n",
        "    \n",
        "    Returns: NO return. But it prints out the loss during training process\n",
        "             and accuracy of val and test set for the model\n",
        "    \"\"\"\n",
        "    # the 4 csv files contain different features and classes\n",
        "    input_dim = X_data.shape[1]\n",
        "    num_class = len(class_dict_1)\n",
        "    \n",
        "    train_dataloader, valid_dataloader, test_dataloader = createLoader(X_data,Y_data,batch_size)\n",
        "    \n",
        "    model1 = None\n",
        "    # define and modify the architecture\n",
        "    model1 = nn.Sequential(\n",
        "        #nn.BatchNorm1d(input_dim),\n",
        "        nn.Linear(input_dim, hidden_layer_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_layer_size, num_class),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.SGD(model1.parameters(), lr=learning_rate,\n",
        "                     momentum=0.9, nesterov=True)\n",
        "\n",
        "    train_part34(model1, train_dataloader, valid_dataloader, optimizer, epochs=epochs)\n",
        "    check_accuracy_part34(test_dataloader, model1)\n",
        "    print('*'*60)\n",
        "\n",
        "#test Model1 upon 4 csv files\n",
        "print('*'*60)\n",
        "testModel1(X_data_1, Y_data_1, class_dict_1)\n",
        "testModel1(X_data_2, Y_data_2, class_dict_2)\n",
        "testModel1(X_data_3, Y_data_3, class_dict_3)\n",
        "testModel1(X_data_4, Y_data_4, class_dict_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "885ad61a",
      "metadata": {
        "id": "885ad61a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d1cd22e",
      "metadata": {
        "id": "6d1cd22e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d9058df",
      "metadata": {
        "id": "4d9058df"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DeepLearning",
      "language": "python",
      "name": "deeplearning"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}